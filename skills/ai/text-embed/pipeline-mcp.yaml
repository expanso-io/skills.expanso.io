# Expanso Pipeline: text-embed (MCP mode)
# =========================================
#
# HTTP endpoint for embedding generation.
#
# Usage:
#   PORT=8080 expanso-edge run pipeline-mcp.yaml
#
#   curl -X POST http://localhost:8080/embed \
#     -H "Content-Type: application/json" \
#     -d '{"text": "Your text here"}'
#
# Validates against: docs.expanso.io/schemas/pipeline.schema.json

name: text-embed-mcp
type: pipeline

config:
  http:
    enabled: true
    address: "0.0.0.0:${PORT:-8080}"

  input:
    http_server:
      path: /embed
      allowed_verbs: [POST]
      timeout: 30s

  pipeline:
    processors:
      # 1. Parse and validate
      - mapping: |
          let text = this.text.or(content())
          root = if $text.length() == 0 {
            throw("text field is required")
          } else if $text.length() > 32768 {
            throw("text exceeds maximum length of 32KB")
          } else {
            $text
          }
          meta input_hash = $text.hash("sha256").encode("hex")
          meta input_length = $text.length()
          meta trace_id = uuid_v4()

      # 2. Generate embedding
      - openai_embeddings:
          api_key: "${OPENAI_API_KEY}"
          model: text-embedding-3-small

      # 3. Format response
      - mapping: |
          root.embedding = this.data.0.embedding
          root.metadata = {
            "skill": "text-embed",
            "mode": "mcp",
            "model": "text-embedding-3-small",
            "dimensions": this.data.0.embedding.length(),
            "input_hash": meta("input_hash"),
            "input_length": meta("input_length"),
            "usage": this.usage,
            "trace_id": meta("trace_id"),
            "timestamp": now()
          }

      - log:
          level: INFO
          message: |
            [text-embed] MCP request: ${! meta("input_length") } chars (trace: ${! meta("trace_id").slice(0, 8) })

  output:
    sync_response: {}

selector:
  match_labels:
    capability: llm
