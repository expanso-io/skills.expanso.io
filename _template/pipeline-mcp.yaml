# Expanso Pipeline: {{SKILL_NAME}} (MCP mode)
# =============================================
#
# Exposes HTTP endpoint for MCP/OpenClaw integration.
#
# Usage:
#   PORT=8080 expanso-edge run pipeline-mcp.yaml
#   curl -X POST http://localhost:8080/process -d '{"text": "your input"}'
#
# Why this matters:
#   OpenClaw's MCP server calls this endpoint, which runs on YOUR machine.
#   Your API keys (OPENAI_API_KEY, etc.) are resolved locally by Expanso Edge.
#   The MCP server never sees your credentials - it only receives results.
#
# Validates against: docs.expanso.io/schemas/pipeline.schema.json

name: "{{SKILL_NAME}}-mcp"
type: pipeline

config:
  # HTTP server configuration
  http:
    enabled: true
    address: "0.0.0.0:${PORT:-8080}"

  input:
    http_server:
      path: /process
      allowed_verbs: [POST]
      timeout: 60s

  pipeline:
    processors:
      # 1. Parse JSON body and prepare with audit metadata
      - mapping: |
          # Extract text from JSON body (or use raw content)
          let input_text = this.text.or(content())

          # Audit metadata
          meta input_hash = $input_text.hash("sha256").encode("hex")
          meta input_length = $input_text.length()
          meta trace_id = uuid_v4()

          # Prepare for LLM (customize this for your skill)
          root.messages = [
            {
              "role": "system",
              "content": "You are a helpful assistant. Process the following input."
            },
            {
              "role": "user",
              "content": $input_text
            }
          ]

      # 2. Call LLM (credentials resolved locally by Expanso Edge)
      - openai_chat_completion:
          api_key: "${OPENAI_API_KEY}"
          model: gpt-4o-mini

      # 3. Format response with metadata
      - mapping: |
          root.result = this.choices.0.message.content
          root.metadata = {
            "skill": "{{SKILL_NAME}}",
            "mode": "mcp",
            "model": "gpt-4o-mini",
            "input_hash": meta("input_hash"),
            "input_length": meta("input_length"),
            "trace_id": meta("trace_id"),
            "timestamp": now()
          }

      # 4. Audit log
      - log:
          level: INFO
          message: |
            [{{SKILL_NAME}}] MCP request processed (trace: ${! meta("trace_id").slice(0, 8) })

  output:
    # Return response synchronously to HTTP caller
    sync_response: {}

# Optional: Node selection for Expanso Cloud deployment
selector:
  match_labels:
    capability: llm
