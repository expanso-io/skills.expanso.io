# Expanso Pipeline: {{SKILL_NAME}} (CLI mode)
# ============================================
#
# Usage:
#   echo "your input" | expanso-edge run pipeline-cli.yaml
#
# Credentials stay local - ${OPENAI_API_KEY} is resolved on your edge node,
# never transmitted to Expanso Cloud or any AI service's orchestration layer.
#
# Validates against: docs.expanso.io/schemas/pipeline.schema.json

name: "{{SKILL_NAME}}-cli"
type: pipeline

config:
  input:
    stdin:
      codec: lines
      max_buffer: 1048576  # 1MB max input

  pipeline:
    processors:
      # 1. Prepare input with audit metadata
      - mapping: |
          # Preserve original input for audit trail
          meta input_hash = content().hash("sha256").encode("hex")
          meta input_length = content().length()
          meta trace_id = uuid_v4()

          # Prepare for LLM (customize this for your skill)
          root.messages = [
            {
              "role": "system",
              "content": "You are a helpful assistant. Process the following input."
            },
            {
              "role": "user",
              "content": content()
            }
          ]

      # 2. Call LLM (credentials resolved locally by Expanso Edge)
      - openai_chat_completion:
          api_key: "${OPENAI_API_KEY}"
          model: gpt-4o-mini

      # 3. Format output with metadata
      - mapping: |
          root.result = this.choices.0.message.content
          root.metadata = {
            "skill": "{{SKILL_NAME}}",
            "mode": "cli",
            "model": "gpt-4o-mini",
            "input_hash": meta("input_hash"),
            "input_length": meta("input_length"),
            "trace_id": meta("trace_id"),
            "timestamp": now()
          }

      # 4. Audit log (appears in expanso-edge logs, not output)
      - log:
          level: INFO
          message: |
            [{{SKILL_NAME}}] Processed ${! meta("input_length") } chars (trace: ${! meta("trace_id").slice(0, 8) })

  output:
    stdout:
      codec: json_object
